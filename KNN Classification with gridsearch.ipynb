{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# packages for plotting\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Generating Data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.keys())\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# data features\n",
    "print(cancer.data.shape)\n",
    "print(cancer.feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# target values\n",
    "print(cancer.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n"
     ]
    }
   ],
   "source": [
    "print(cancer.data.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X = cancer.data\n",
    "Y = cancer.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "# finding the best K\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "k_choices = list([5,10,15,20,25])\n",
    "param_grid = dict(n_neighbors=k_choices)\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "grid_search=grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 10}\n",
      "0.972027972027972\n",
      "0.9270861833105336\n"
     ]
    }
   ],
   "source": [
    "# show the best k chosen\n",
    "print(grid_search.best_params_) #k=10\n",
    "\n",
    "# the test accuracy under the best model\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn.score(X_test, y_test)) \n",
    "\n",
    "#the mean validation accuracy\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "# Part II. Regression Models\n",
    "\n",
    "In this part, you are required to analyze the daily version of the [Capital Bikeshare System dataset](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset) from the UCI Machine Learning Repository. This data set contains information about the daily count of bike rental checkouts in Washington, D.C.â€™s bikeshare program between 2011 and 2012. It also includes information about the weather and seasonal/temporal features for that day (e.g., if it was a weekday).\n",
    "- **day:** Day of the record (relative to day 1: 2011-01-01)\n",
    "- **season:** Season (1: spring, 2: summer, 3: fall, 4: winter)\n",
    "- **weekday:** Day of the week (0 = Sunday, 6 = Saturday)\n",
    "- **workingday:** If day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "- **weathersit:**<br>\n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered\n",
    "clouds\n",
    "- **temp:** Normalized temperature in Celsius\n",
    "- **windspeed:** Normalized wind speed\n",
    "- **casual:** Count of checkouts by casual/non-registered users\n",
    "- **registered:** Count of checkouts by registered users\n",
    "- **cnt:** Total checkouts\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Run the cells below to load the split the data. We will use features ('weekday', 'season','workingday', 'temp', 'windspeed', 'weathersit') to predict the checkout counts. We are interested in predicting the total checkout counts (i.e., 'cnt')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instant' 'day' 'season' 'weekday' 'workingday' 'weathersit' 'temp'\n",
      " 'windspeed' 'casual' 'registered' 'cnt']\n"
     ]
    }
   ],
   "source": [
    "day = pd.read_csv(\"day.csv\")\n",
    "print(day.columns.values) # to find variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day.head()\n",
    "day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['weekday', 'season','workingday', 'temp', 'windspeed', 'weathersit']\n",
    "X = day[var]\n",
    "y = day['cnt']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3a | Lasso Regression (20 pts)\n",
    "\n",
    "- Train a Lasso regression model using the training set with alpha = 50. We would like to use MSE as the performance measure. What is the MSE for the test set?  What is the MSE for training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042360.3510422485\n",
      "1960999.2636079753\n"
     ]
    }
   ],
   "source": [
    "#training the Lasso regression model\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "Lasso_reg = Lasso(alpha=50)\n",
    "Lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "#prediction for the test set\n",
    "\n",
    "y_pred_test_Lasso = Lasso_reg.predict(X_test)\n",
    "\n",
    "y_pred_test_Lasso\n",
    "\n",
    "#mse for the test set\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "print (mse(y_test, y_pred_test_Lasso))\n",
    "\n",
    "#prediction for the train set\n",
    "y_pred_train_Lasso = Lasso_reg.predict(X_train)\n",
    "\n",
    "y_pred_train_Lasso\n",
    "#mse for the train set\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "print (mse(y_train, y_pred_train_Lasso))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3b | Parameters (5 pts)\n",
    "- Report the coefficients and the intercept of the above Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  66.42091432,  484.36577205,    0.        , 3785.62747889,\n",
       "          -0.        , -698.48336419]),\n",
       " 2242.206958517444)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = Lasso_reg.coef_\n",
    "intercept = Lasso_reg.intercept_\n",
    "\n",
    "coef, intercept\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 | Ridge Regression (10 pts)\n",
    "\n",
    "- For the same dataset, train a Ridge regression model with lambda (i.e., hyperparameter) = 0.05. Report the coefficient and intercept of the Ridge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  66.42091432,  484.36577205,    0.        , 3785.62747889,\n",
       "          -0.        , -698.48336419]),\n",
       " 2242.206958517444)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=0.05)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test_ridge = ridge_reg.predict(X_test)\n",
    "\n",
    "y_pred_test_ridge\n",
    "\n",
    "\n",
    "coef = Lasso_reg.coef_\n",
    "intercept = Lasso_reg.intercept_\n",
    "\n",
    "coef, intercept\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>After inspecting the data, we have found that the total checkouts is the sum of the casual checkouts and registered checkouts. That is, cnt = casual + registered. We believe that the checkout behavior of the two groups of users (i.e., registered vs. casual) would be significantly different. Therefore, we want to predict casual and registered checkout separately. For simplicity, we use linear regression models.\n",
    "\n",
    "Run the cell below for data splitting. *(Hint: prefix `yr_` represents y for registered, prefix `yc_` represents y for casual, prefix `yt_` represents y for total checkout).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3c | Report (10 pts)\n",
    "\n",
    "- Based on the current model, which feature(s) are not useful in predicting the outcome (y)? Explain Briefly. **Maximum 3 sentences**\n",
    "\n",
    "<br><br>\n",
    "#### WRITE YOUR ANSWER HERE\n",
    "workingday and windspeed are the features that are not useful in predicting the outcome cnt. This ie because the Lasso regression reduced their coefficients to zero meaning they increased vraiance but have no significant i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (82610416.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    workingday and windspeed are the features that are not useful in predicting the outcome cnt. This ie because the Lasso regression reduced their coefficients to zero meaning they increased vraiance but have no significant\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "workingday and windspeed are the features that are not useful in predicting the outcome cnt. This ie because the Lasso regression reduced their coefficients to zero meaning they increased vraiance but have no significant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['weekday', 'season','workingday', 'temp', 'windspeed', 'weathersit']\n",
    "var_ys = ['registered', 'casual', 'cnt']\n",
    "\n",
    "X = day[var]\n",
    "ys = day[var_ys]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, ys_train, ys_test = train_test_split(X, ys, test_size=0.25, random_state=42)\n",
    "\n",
    "yr_train, yc_train, yt_train = ys_train['registered'], ys_train['casual'], ys_train['cnt']\n",
    "yr_test, yc_test, yt_test  = ys_test['registered'], ys_test['casual'], ys_test['cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5a | Linear Regression (10 pts)\n",
    "\n",
    "- Train a linear model. Let X be ['weekday', 'season','workingday', 'temp', 'windspeed', 'weathersit']. Let y be registered checkout count. Report the coefficients of variables (no need to report the intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "modelr = LinearRegression()\n",
    "# Train the model using the training set\n",
    "modelr.fit(X_train, yr_train)\n",
    "# Coefficients\n",
    "coef = modelr.coef_\n",
    "coef\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5b | Linear Regression Extended (5 pts)\n",
    "- Train another linear model. Let X be ['weekday', 'season','workingday', 'temp', 'windspeed', 'weathersit']. Let y be casual checkout count. Report the coefficients of variables (no need to report the intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelc = LinearRegression()\n",
    "# Train the model using the training set\n",
    "modelc.fit(X_train, yc_train)\n",
    "# Coefficients\n",
    "coef = modelc.coef_\n",
    "coef\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5c | Explanation 8 pts)\n",
    "- Based on the results, we find that one variable has opposite impact on casual checkout count and registered checkout count. What is the variable? Explain briefly. **Maximum 2 sentences**\n",
    "<br><br><br>\n",
    "\n",
    "#### WRITE YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "The varaiable is working day; it has a postive relationship with registered checkouts and a negative relationship with casual checkouts! there more checkouts on working day for registered checkouts and less casual checkouts on workdays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The varaiable is working day; it has a postive relationship with registered checkouts and a negative relationship with casual checkouts! there more checkouts on working day for registered checkouts and less casual checkouts on workdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
